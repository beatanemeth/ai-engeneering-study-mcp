{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and Configuration\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# Define relative paths\n",
    "INPUT_FILE_ARTICLES = \"../data/wix_articles_data.json\"\n",
    "INPUT_FILE_CATEGORIES = \"../data/wix_articles-category_data.json\"\n",
    "OUTPUT_FOLDER = \"../data_prepared/\"\n",
    "OUTPUT_FILE = os.path.join(OUTPUT_FOLDER, \"articles.json\")\n",
    "\n",
    "# Simple check to verify the files is where we think they are\n",
    "if os.path.exists(INPUT_FILE_ARTICLES ):\n",
    "    print(f\"‚úÖ Setup complete. Input files found: {INPUT_FILE_ARTICLES}\")\n",
    "else:\n",
    "    print(f\"‚ùå Warning: Input file NOT found at {INPUT_FILE_ARTICLES }\")\n",
    "\n",
    "if os.path.exists(INPUT_FILE_CATEGORIES ):\n",
    "    print(f\"‚úÖ Setup complete. Input files found: {INPUT_FILE_CATEGORIES }\")\n",
    "else:\n",
    "    print(f\"‚ùå Warning: Input file NOT found at {INPUT_FILE_CATEGORIES }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading for Article\n",
    "\n",
    "if not os.path.exists(OUTPUT_FOLDER):\n",
    "    os.makedirs(OUTPUT_FOLDER)\n",
    "    print(f\"Created folder: {OUTPUT_FOLDER}\")\n",
    "\n",
    "try:\n",
    "    with open(INPUT_FILE_ARTICLES, 'r', encoding='utf-8') as f:\n",
    "        raw_json_ptr = json.load(f)\n",
    "    \n",
    "    # Extract the 'items' list and convert to DataFrame\n",
    "    # Using .get() prevents a crash if 'items' is missing\n",
    "    articles_df = pd.DataFrame(raw_json_ptr.get('items', []))\n",
    "    \n",
    "    if not articles_df.empty:\n",
    "        print(f\"‚úÖ Successfully loaded {len(articles_df)} records from 'items'.\")\n",
    "        print(\"\\n--- First 3 rows of raw data ---\")\n",
    "        display(articles_df.head(3))\n",
    "        \n",
    "        # Pro-tip: df.columns.tolist() is a bit cleaner for printing\n",
    "        print(\"\\nAvailable columns:\", *articles_df.columns, sep=\"\\n\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è The 'items' list was empty or missing.\")\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå Error: The file {INPUT_FILE_ARTICLES} was not found.\")\n",
    "except json.JSONDecodeError:\n",
    "    print(f\"‚ùå Error: {INPUT_FILE_ARTICLES} contains invalid JSON formatting.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation Logic\n",
    "\n",
    "# Use .assign() to create the new DataFrame with all logic in one block.\n",
    "final_articles_df = articles_df.assign(\n",
    "    id=articles_df['_id'],\n",
    "    title=articles_df['title'],\n",
    "    excerpt=articles_df['lead'],\n",
    "    contentText=articles_df['articletext'],\n",
    "    categoryId=articles_df['category'],\n",
    "    author=\"Dr. Prezenszki Zsuzsanna\",\n",
    "    \n",
    "    # Handle Tags: Ensure data is a list using a list comprehension\n",
    "    tags=[x if isinstance(x, list) else [] for x in articles_df['arraystring']],\n",
    "    \n",
    "    # Handle Date: Convert to datetime and format as YYYY-MM-DD\n",
    "    publishedDate=pd.to_datetime(articles_df['_createdDate']).dt.date.astype(str),\n",
    "    \n",
    "    # Construct URL: Use f-string style formatting or simple concatenation\n",
    "    url=\"https://www.kiutarakbol.hu/tudastar/\" + \n",
    "        articles_df['urlvege1'].astype(str) + \"/\" + \n",
    "        articles_df['urlvege'].astype(str)\n",
    ")\n",
    "\n",
    "# Reorder & Finalize\n",
    "# We define the order we want and filter the DataFrame to only those columns.\n",
    "final_columns = [\n",
    "    'id', 'title', 'excerpt', 'contentText', 'categoryId', \n",
    "    'tags', 'publishedDate', 'url', 'author'\n",
    "]\n",
    "final_articles_df = final_articles_df[final_columns]\n",
    "\n",
    "print(f\"Transformation complete. Processed {len(final_articles_df)} articles.\")\n",
    "display(final_articles_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean_ HTML tags from the blog body text\n",
    "\n",
    "def clean_wix_html(raw_html):\n",
    "    \"\"\"\n",
    "    Parses raw HTML string, removes boilerplate tags/scripts, \n",
    "    and returns a clean, human-readable text string.\n",
    "    \"\"\"\n",
    "    # Check for null values or non-string data to prevent crashes during processing\n",
    "    if not raw_html or not isinstance(raw_html, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Initialize BeautifulSoup with the standard HTML parser\n",
    "    soup = BeautifulSoup(raw_html, \"html.parser\")\n",
    "\n",
    "    # Remove 'script' and 'style' tags entirely so their internal code \n",
    "    # (Javascript/CSS) doesn't get extracted as readable text\n",
    "    for script_or_style in soup([\"script\", \"style\"]):\n",
    "        script_or_style.decompose()\n",
    "\n",
    "    # Extract text from the HTML tags; use '\\n' as a separator \n",
    "    # to prevent block elements (like <div> or <p>) from merging into one word\n",
    "    text = soup.get_text(separator=\"\\n\")\n",
    "    \n",
    "    # Replace the non-breaking space entity (\\xa0) with a standard space\n",
    "    text = text.replace('\\xa0', ' ')\n",
    "    \n",
    "    # Use Regex to find multiple consecutive newlines (possibly containing spaces)\n",
    "    # and collapse them into exactly two newlines for clean paragraph spacing\n",
    "    text = re.sub(r'\\n\\s*\\n+', '\\n\\n', text)\n",
    "    \n",
    "    # Remove leading and trailing whitespace from the final result\n",
    "    return text.strip()\n",
    "\n",
    "# Apply the cleaning function to every row in the 'contentText' column\n",
    "final_articles_df['contentText'] = final_articles_df['contentText'].apply(clean_wix_html)\n",
    "\n",
    "print(\"‚úÖ HTML Cleaning complete.\")\n",
    "display(final_articles_df[['title', 'contentText']].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map Category IDs to Human-Readable Labels \n",
    "\n",
    "# Load the category metadata to build a translation map\n",
    "with open(INPUT_FILE_CATEGORIES, 'r', encoding='utf-8') as f:\n",
    "    categories_json = json.load(f)\n",
    "    categories_raw = categories_json.get('items', [])\n",
    "\n",
    "# Create a fast lookup dictionary: { 'unique-id-123': 'Health & Wellness' }\n",
    "categories_lookup = {cat['_id']: cat['title'] for cat in categories_raw}\n",
    "\n",
    "# Define translation logic to handle both single strings and lists of IDs\n",
    "def translate_category(category_val):\n",
    "    # If the cell contains a list of IDs, translate each item in the list\n",
    "    if isinstance(category_val, list):\n",
    "        return [categories_lookup.get(c_id, c_id) for c_id in category_val]\n",
    "    # Otherwise, translate the single ID; return the ID itself if not found in lookup\n",
    "    return categories_lookup.get(category_val, category_val)\n",
    "\n",
    "# Dynamic Column Selection: Ensure we are targeting the right field name\n",
    "target_col = 'categoryId' if 'categoryId' in final_articles_df.columns else 'category'\n",
    "\n",
    "# Map the IDs to names across the entire DataFrame\n",
    "final_articles_df[target_col] = final_articles_df[target_col].apply(translate_category)\n",
    "\n",
    "# Standardize the column name to 'category' for the final output\n",
    "if target_col == 'categoryId':\n",
    "    final_articles_df = final_articles_df.rename(columns={'categoryId': 'category'})\n",
    "\n",
    "print(f\"‚úÖ Categories processed. Sample lookup: {list(categories_lookup.values())[:2]}\")\n",
    "display(final_articles_df[['title', 'category']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to JSON (keeping Hungarian characters safe with ensure_ascii=False)\n",
    "final_articles_df.to_json(OUTPUT_FILE, orient='records', force_ascii=False, indent=4)\n",
    "print(f\"üöÄ Data successfully exported to {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (AI Engineering)",
   "language": "python",
   "name": "ai-engeneering-study-mcp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
