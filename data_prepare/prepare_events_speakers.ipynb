{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and Configuration\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "# Define relative paths\n",
    "INPUT_FILE_EVENTS = \"../data_prepared/events_intermediate.json\"\n",
    "OUTPUT_FOLDER = \"../data_prepared/\"\n",
    "OUTPUT_FILE = os.path.join(OUTPUT_FOLDER, \"events.json\")\n",
    "\n",
    "# Simple check to verify the file is where we think it is\n",
    "if os.path.exists(INPUT_FILE_EVENTS):\n",
    "    print(f\"‚úÖ Setup complete. Input file found: {INPUT_FILE_EVENTS}\")\n",
    "else:\n",
    "    print(f\"‚ùå Warning: Input file NOT found at {INPUT_FILE_EVENTS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading and Directory Check\n",
    "# Ensure the output directory exists\n",
    "if not os.path.exists(OUTPUT_FOLDER):\n",
    "    os.makedirs(OUTPUT_FOLDER)\n",
    "    print(f\"Created folder: {OUTPUT_FOLDER}\")\n",
    "\n",
    "# Load the raw data\n",
    "try:\n",
    "    events_df = pd.read_json(INPUT_FILE_EVENTS)\n",
    "    print(f\"Successfully loaded {len(events_df)} records.\")\n",
    "    \n",
    "    display(events_df.head(3)) \n",
    "    \n",
    "    print(\"\\nAvailable columns:\", *events_df.columns, sep=\"\\n\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file {INPUT_FILE_EVENTS} was not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the speaker column with an empty string as the default value\n",
    "events_df['speaker'] = \"\"\n",
    "\n",
    "# Define the final column order\n",
    "final_columns = ['id', 'title', 'date', 'speaker', 'location', 'categories', 'eventGuests', 'descriptionText', 'url']\n",
    "\n",
    "# Reorder the DataFrame based on final_columns\n",
    "# We use .copy() to avoid SettingWithCopy warnings if you perform further operations\n",
    "events_df = events_df[final_columns].copy()\n",
    "\n",
    "print(\"‚úÖ Added 'speaker' column and reordered columns.\")\n",
    "print(f\"New shape: {events_df.shape}\")\n",
    "\n",
    "display(events_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reusable function\n",
    "\n",
    "def extract_snippet(text, keyword, length=500):\n",
    "    \"\"\"\n",
    "    Finds a keyword in text (case-insensitive) and returns \n",
    "    the keyword plus the following N characters.\n",
    "    \"\"\"\n",
    "\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    \n",
    "    # Handle non-string data (like NaN or None) safely\n",
    "    if not isinstance(text, str):\n",
    "        return None\n",
    "    \n",
    "    # re.escape handles special characters in the keyword (e.g. ?, ., *)\n",
    "    # re.IGNORECASE makes it find \"ki vezeti\", \"Ki Vezeti\", etc.\n",
    "    match = re.search(re.escape(keyword), text, re.IGNORECASE)\n",
    "    \n",
    "    if match:\n",
    "        start_index = match.start()\n",
    "        # Return the match + the specified number of characters\n",
    "        return text[start_index : start_index + len(keyword) + length]\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter descriptionText column for this term:'ki vezeti'\n",
    "search_term_1 = \"ki vezeti\"\n",
    "\n",
    "# Filter the dataframe (case-insensitive search)\n",
    "filtered_1_df = events_df[events_df['descriptionText'].str.contains(search_term_1, case=False, na=False)].copy()\n",
    "\n",
    "# Create a new column 'snippet' with the text found\n",
    "filtered_1_df['snippet'] = filtered_1_df['descriptionText'].apply(\n",
    "    lambda x: extract_snippet(x, search_term_1)\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Found {len(filtered_1_df)} matches.\")\n",
    "\n",
    "display(filtered_1_df[['id', 'title', 'snippet']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the 'speaker' column using the index of your filtered results\n",
    "events_df.loc[filtered_1_df.index, 'speaker'] = \"Dr. Prezenszki Zsuzsanna\"\n",
    "\n",
    "# Print the number of updated rows\n",
    "print(f\"‚úÖ Updated {len(filtered_1_df)} rows with the new speaker.\")\n",
    "\n",
    "# Count events with and without a speaker\n",
    "total_has_speaker = (events_df['speaker'] != \"\").sum()\n",
    "total_no_speaker = (events_df['speaker'] == \"\").sum()\n",
    "\n",
    "print(f\"üìä Global Speaker Statistics (Total Dataset):\")\n",
    "print(f\"    - Events with a speaker: {total_has_speaker}\")\n",
    "print(f\"    - Events without a speaker: {total_no_speaker}\")\n",
    "print(f\"    - Total events: {len(events_df)}\")\n",
    "\n",
    "display(events_df.loc[filtered_1_df.index, ['id', 'title', 'speaker']].head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter descriptionText column for this term:'ki seg√≠t neked'\n",
    "search_term_2 = \"ki seg√≠t neked\"\n",
    "\n",
    "# Filter: Text contains keyword AND speaker is empty (\"\")\n",
    "mask = (events_df['descriptionText'].str.contains(search_term_2, case=False, na=False)) & \\\n",
    "       (events_df['speaker'] == \"\")\n",
    "\n",
    "# Create the filtered dataframe\n",
    "filtered_2_df = events_df[mask].copy()\n",
    "\n",
    "# Extract snippets only for these specific rows\n",
    "filtered_2_df['snippet'] = filtered_2_df['descriptionText'].apply(lambda x: extract_snippet(x, search_term_2, length=550))\n",
    "\n",
    "print(f\"‚úÖ Found {len(filtered_2_df)} matches with no speaker assigned.\")\n",
    "display(filtered_2_df[['id', 'title', 'snippet']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sub-filter term\n",
    "sub_search_term_2_matuszka = \"Matuszka\"\n",
    "\n",
    "# We use case=False to be safe (catches \"Matuszka\", \"MATUSZKA\", etc.)\n",
    "filtered_matuszka_df = filtered_2_df[filtered_2_df['descriptionText'].str.contains(sub_search_term_2_matuszka, case=False, na=False)].copy()\n",
    "\n",
    "# Print the counts\n",
    "print(f\"üìä Filtering Results:\")\n",
    "print(f\"   - Total rows in filtered_2_df: {len(filtered_2_df)}\")\n",
    "print(f\"   - Rows specifically mentioning '{sub_search_term_2_matuszka}': {len(filtered_matuszka_df)}\")\n",
    "\n",
    "display(filtered_matuszka_df[['id', 'title', 'speaker', 'snippet']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the 'speaker' column in the main DataFrame\n",
    "events_df.loc[filtered_matuszka_df.index, 'speaker'] = \"Dr. Matuszka Istv√°n\"\n",
    "\n",
    "# Print the number of updated rows\n",
    "print(f\"‚úÖ Updated {len(filtered_matuszka_df)} rows with the new speaker.\")\n",
    "\n",
    "# Statistics specifically for the CURRENT working batch (filtered_2_df)\n",
    "# This helps to see how much of 'ki seg√≠t neked' is left to process\n",
    "batch_filtered_2_has_speaker = (events_df.loc[filtered_2_df.index, 'speaker'] != \"\").sum()\n",
    "batch_filtered_2_no_speaker = (events_df.loc[filtered_2_df.index, 'speaker'] == \"\").sum()\n",
    "\n",
    "print(f\"üìä Batch Statistics ('ki seg√≠t neked' group):\")\n",
    "print(f\"   - Already assigned in this batch: {batch_filtered_2_has_speaker}\")\n",
    "print(f\"   - Remaining to assign in this batch: {batch_filtered_2_no_speaker}\")\n",
    "\n",
    "print(\"\\n‚úÖ Verification of updated 'Matuszka' rows:\")\n",
    "display(events_df.loc[filtered_matuszka_df.index, ['id', 'title', 'speaker']].head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a fresh filter from the main DataFrame where Speaker is empty and Text contains the keyword\n",
    "mask_remaining = (events_df['speaker'] == \"\") & \\\n",
    "                 (events_df['descriptionText'].str.contains(search_term_2, case=False, na=False))\n",
    "\n",
    "# Create the new DataFrame based on the live data\n",
    "rest_filtered_2_df = events_df[mask_remaining].copy()\n",
    "\n",
    "# Add the snippet so you can see the context\n",
    "rest_filtered_2_df['snippet'] = rest_filtered_2_df['descriptionText'].apply(\n",
    "    lambda x: extract_snippet(x, search_term_2, length=500)\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Found {len(rest_filtered_2_df)} total events matching '{search_term_2}' that still need a speaker.\")\n",
    "\n",
    "display(rest_filtered_2_df[['id', 'title', 'snippet']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter \n",
    "sub_search_term_2_andrea_1 = \"vezet≈ëje: Gy≈ërfi Andrea, klinikai szakpszichol√≥gus\"\n",
    "sub_search_term_2_andrea_2 = \"vezet≈ëje:\\n‚ÄãGy≈ërfi Andrea, pszichol√≥gus\"\n",
    "\n",
    "mask_andrea_clean = (rest_filtered_2_df['descriptionText'].str.contains(sub_search_term_2_andrea_1, case=False)) | \\\n",
    "       (rest_filtered_2_df['descriptionText'].str.contains(sub_search_term_2_andrea_2, case=False))\n",
    "\n",
    "# Create the filtered dataframe\n",
    "filtered_df_andrea = rest_filtered_2_df[mask_andrea_clean].copy()\n",
    "\n",
    "# Print the counts\n",
    "print(f\"üìä Filtering Results:\")\n",
    "print(f\"   - Total rows in rest_filtered_2_df: {len(rest_filtered_2_df)}\")\n",
    "print(f\"   - Rows specifically mentioning '{sub_search_term_2_andrea_1}' or '{sub_search_term_2_andrea_2}': {len(filtered_df_andrea)}\")\n",
    "\n",
    "display(filtered_df_andrea[['id', 'title', 'speaker', 'snippet']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the 'speaker' column in the main DataFrame\n",
    "events_df.loc[filtered_df_andrea.index, 'speaker'] = \"Gy≈ërfi Andrea\"\n",
    "\n",
    "# Statistics specifically for the CURRENT working batch (filtered_2_df)\n",
    "# This helps to see how much of 'ki seg√≠t neked' is left to process\n",
    "batch_filtered_2_has_speaker = (events_df.loc[filtered_2_df.index, 'speaker'] != \"\").sum()\n",
    "batch_filtered_2_no_speaker = (events_df.loc[filtered_2_df.index, 'speaker'] == \"\").sum()\n",
    "\n",
    "print(f\"üìä Batch Statistics ('ki seg√≠t neked' group):\")\n",
    "print(f\"   - Already assigned in this batch: {batch_filtered_2_has_speaker}\")\n",
    "print(f\"   - Remaining to assign in this batch: {batch_filtered_2_no_speaker}\")\n",
    "\n",
    "print(\"\\n‚úÖ Verification of updated 'Gy≈ërfi Andrea' rows:\")\n",
    "display(events_df.loc[filtered_df_andrea.index, ['id', 'title', 'speaker']].head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a fresh filter from the main DataFrame where Speaker is empty and Text contains the keyword\n",
    "mask_remaining = (events_df['speaker'] == \"\") & \\\n",
    "                 (events_df['descriptionText'].str.contains(search_term_2, case=False, na=False))\n",
    "\n",
    "# Create the new DataFrame based on the live data\n",
    "rest_filtered_2_df = events_df[mask_remaining].copy()\n",
    "\n",
    "# Add the snippet so you can see the context\n",
    "rest_filtered_2_df['snippet'] = rest_filtered_2_df['descriptionText'].apply(\n",
    "    lambda x: extract_snippet(x, search_term_2, length=500)\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Found {len(rest_filtered_2_df)} total events matching '{search_term_2}' that still need a speaker.\")\n",
    "\n",
    "display(rest_filtered_2_df[['id', 'title', 'snippet']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the 'speaker' column in the main DataFrame\n",
    "events_df.loc[rest_filtered_2_df.index, 'speaker'] = \"Dr. Prezenszki Zsuzsanna\"\n",
    "\n",
    "# Statistics for the WHOLE project (events_df)\n",
    "total_has_speaker = (events_df['speaker'] != \"\").sum()\n",
    "total_no_speaker = (events_df['speaker'] == \"\").sum()\n",
    "\n",
    "# Statistics specifically for the CURRENT working batch (filtered_2_df)\n",
    "# This helps to see how much of 'ki seg√≠t neked' is left to process\n",
    "batch_filtered_2_has_speaker = (events_df.loc[filtered_2_df.index, 'speaker'] != \"\").sum()\n",
    "batch_filtered_2_no_speaker = (events_df.loc[filtered_2_df.index, 'speaker'] == \"\").sum()\n",
    "\n",
    "print(f\"üìä Global Speaker Statistics (Total Dataset):\")\n",
    "print(f\"   - Events with a speaker: {total_has_speaker}\")\n",
    "print(f\"   - Events without a speaker: {total_no_speaker}\")\n",
    "print(f\"   - Total events: {len(events_df)}\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"üìä Batch Statistics ('ki seg√≠t neked' group):\")\n",
    "print(f\"   - Already assigned in this batch: {batch_filtered_2_has_speaker}\")\n",
    "print(f\"   - Remaining to assign in this batch: {batch_filtered_2_no_speaker}\")\n",
    "\n",
    "print(\"\\n‚úÖ Verification of updated 'Gy≈ërfi Andrea' rows:\")\n",
    "display(events_df.loc[rest_filtered_2_df.index, ['id', 'title', 'speaker']].head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter descriptionText column for this term:\n",
    "search_term_3 = \"Czimer Gy√∂rgyi\"\n",
    "search_term_3_a = \"Er≈ëforr√°sgy≈±jt≈ë H√©tv√©ge\"\n",
    "search_term_3_b = \"Csob√°nkai Er≈ëforr√°st√°bor\"\n",
    "\n",
    "mask_filtered_3_df = (\n",
    "    (events_df['descriptionText'].str.contains(search_term_3, case=False, na=False)) & \n",
    "    (~events_df['title'].str.contains(search_term_3_a, case=False, na=False)) & \n",
    "    (~events_df['title'].str.contains(search_term_3_b, case=False, na=False))\n",
    ")\n",
    "\n",
    "filtered_3_df = events_df[mask_filtered_3_df].copy()\n",
    "\n",
    "# Extract snippets\n",
    "filtered_3_df['snippet'] = filtered_3_df['descriptionText'].apply(\n",
    "    lambda x: extract_snippet(x, search_term_3, length=500)\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Found {len(filtered_3_df)} matches.\")\n",
    "display(filtered_3_df[['id', 'title', 'snippet']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the 'speaker' column in the main DataFrame\n",
    "events_df.loc[filtered_3_df.index, 'speaker'] = \"Czimer Gy√∂rgyi\"\n",
    "\n",
    "# Statistics for the WHOLE project (events_df)\n",
    "total_has_speaker = (events_df['speaker'] != \"\").sum()\n",
    "total_no_speaker = (events_df['speaker'] == \"\").sum()\n",
    "\n",
    "print(f\"üìä Global Speaker Statistics (Total Dataset):\")\n",
    "print(f\"   - Events with a speaker: {total_has_speaker}\")\n",
    "print(f\"   - Events without a speaker: {total_no_speaker}\")\n",
    "print(f\"   - Total events: {len(events_df)}\")\n",
    "\n",
    "print(\"\\n‚úÖ Verification of updated 'Czimer Gy√∂rgyi' rows:\")\n",
    "display(events_df.loc[filtered_3_df.index, ['id', 'title', 'speaker']].head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter term\n",
    "search_term_4 = \"T√≥tiv√°n Tibor\"\n",
    "\n",
    "# Apply the mask to events_df to create a proper DataFrame\n",
    "filtered_4_df = events_df[events_df['descriptionText'].str.contains(search_term_4, case=False, na=False)].copy()\n",
    "\n",
    "# Extract snippets (now works because filtered_df_4 is a DataFrame)\n",
    "filtered_4_df['snippet'] = filtered_4_df['descriptionText'].apply(\n",
    "    lambda x: extract_snippet(x, search_term_4, length=250)\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Found {len(filtered_4_df)} matches.\")\n",
    "\n",
    "display(filtered_4_df[['id', 'title', 'snippet']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the 'speaker' column in the main DataFrame\n",
    "events_df.loc[filtered_4_df.index, 'speaker'] = \"T√≥tiv√°n Tibor\"\n",
    "\n",
    "# Statistics for the WHOLE project\n",
    "total_has_speaker = (events_df['speaker'] != \"\").sum()\n",
    "total_no_speaker = (events_df['speaker'] == \"\").sum()\n",
    "\n",
    "print(f\"üìä Global Speaker Statistics (Total Dataset):\")\n",
    "print(f\"   - Events with a speaker: {total_has_speaker}\")\n",
    "print(f\"   - Events without a speaker: {total_no_speaker}\")\n",
    "print(f\"   - Total events: {len(events_df)}\")\n",
    "\n",
    "print(\"\\n‚úÖ Verification of updated 'T√≥tiv√°n Tibor' rows:\")\n",
    "display(events_df.loc[filtered_4_df.index, ['id', 'title', 'speaker']].head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the titles \n",
    "target_titles = [\n",
    "    \"H√≥vir√°gt√∫ra a Normaf√°n\",\n",
    "    \"√ñsszehangolva a Simonton m√≥dszerrel (online, okt. 16.)\",\n",
    "    \"Tavaszi meg√∫jul√°s - Budapest\",\n",
    "    \"√ñsszehangolva a V√°rosligetben - SIMONTON KLUB\"\n",
    "]\n",
    "\n",
    "# Identify the rows where speaker is empty AND title matches our list\n",
    "mask = (events_df['speaker'].isna() | (events_df['speaker'] == \"\")) & (events_df['title'].isin(target_titles))\n",
    "\n",
    "# Apply the update only to those specific rows\n",
    "events_df.loc[mask, 'speaker'] = \"Dr. Prezenszki Zsuzsanna\"\n",
    "\n",
    "print(f\"‚úÖ Successfully updated {mask.sum()} rows.\")\n",
    "\n",
    "display(events_df[events_df['title'].isin(target_titles)][['title', 'speaker']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the summary of speakers\n",
    "speaker_summary = events_df['speaker'].replace(\"\", \"‚ö†Ô∏è MISSING/UNASSIGNED\").value_counts().reset_index()\n",
    "speaker_summary.columns = ['Speaker Name', 'Count']\n",
    "\n",
    "print(\"üìä FINAL PROJECT SUMMARY\")\n",
    "print(\"-\" * 30)\n",
    "display(speaker_summary)\n",
    "\n",
    "print(\"\\nüëÄ DATA PREVIEW (First 5 rows):\")\n",
    "display(events_df[['id', 'title', 'speaker']].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to JSON\n",
    "# force_ascii=False is crucial for keeping Hungarian characters like ≈ë, √∫, √©\n",
    "if pd.api.types.is_datetime64_any_dtype(events_df['date']):\n",
    "    events_df['date'] = events_df['date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# date_format='iso' ensures dates are readable strings\n",
    "# categories will be included as long as they are in the events_df\n",
    "events_df.to_json(\n",
    "    OUTPUT_FILE, \n",
    "    orient='records', \n",
    "    indent=4, \n",
    "    force_ascii=False, \n",
    "    date_format='iso'\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Success! Cleaned data is saved to: {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (AI Engineering)",
   "language": "python",
   "name": "ai-engeneering-study-mcp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
